{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f39_5v4kEAMo"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harmonai-org/sample-generator/blob/main/Finetune_Dance_Diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHcTRGvUmoME"
      },
      "source": [
        "# Dance Diffusion finetune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u97w34BXmust"
      },
      "source": [
        "Licensed under the MIT License\n",
        "\n",
        "Copyright (c) 2022 Zach Evans\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in\n",
        "all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
        "THE SOFTWARE.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU97ZiP7nSKS"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "mxb-qgh0nUOf",
        "outputId": "818fcbbd-0552-4a80-e28b-7b56a2de9318",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-00ddb01c-2415-da34-a7a6-f166e6f38a0c)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Check GPU Status\n",
        "import subprocess\n",
        "simple_nvidia_smi_display = True#@param {type:\"boolean\"}\n",
        "if simple_nvidia_smi_display:\n",
        "    #!nvidia-smi\n",
        "    nvidiasmi_output = subprocess.run(['nvidia-smi', '-L'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_output)\n",
        "else:\n",
        "    #!nvidia-smi -i 0 -e 0\n",
        "    nvidiasmi_output = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_output)\n",
        "    nvidiasmi_ecc_note = subprocess.run(['nvidia-smi', '-i', '0', '-e', '0'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_ecc_note)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "T_mFtzHvnlJL",
        "outputId": "072ca8ee-78e8-4ed7-973b-74103bee7522",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Colab detected. Using Google Drive.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Prepare folders\n",
        "import subprocess, os, sys, ipykernel\n",
        "\n",
        "def gitclone(url, targetdir=None):\n",
        "    if targetdir:\n",
        "        res = subprocess.run(['git', 'clone', url, targetdir], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    else:\n",
        "        res = subprocess.run(['git', 'clone', url], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def pipi(modulestr):\n",
        "    res = subprocess.run(['pip', 'install', modulestr], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def pipie(modulestr):\n",
        "    res = subprocess.run(['git', 'install', '-e', modulestr], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def wget(url, outputdir):\n",
        "    res = subprocess.run(['wget', url, '-P', f'{outputdir}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    print(\"Google Colab detected. Using Google Drive.\")\n",
        "    is_colab = True\n",
        "    google_drive = True #@param {type:\"boolean\"}\n",
        "    #@markdown Click here if you'd like to save the diffusion model checkpoint file to (and/or load from) your Google Drive:\n",
        "    save_models_to_google_drive = True #@param {type:\"boolean\"}\n",
        "except:\n",
        "    is_colab = False\n",
        "    google_drive = False\n",
        "    save_models_to_google_drive = False\n",
        "    print(\"Google Colab not detected.\")\n",
        "\n",
        "if is_colab:\n",
        "    if google_drive is True:\n",
        "        drive.mount('/content/drive')\n",
        "        root_path = '/content/drive/MyDrive/AI/Bass_Diffusion'\n",
        "    else:\n",
        "        root_path = '/content'\n",
        "else:\n",
        "    root_path = os.getcwd()\n",
        "\n",
        "import os\n",
        "def createPath(filepath):\n",
        "    os.makedirs(filepath, exist_ok=True)\n",
        "\n",
        "initDirPath = f'{root_path}/init_audio'\n",
        "createPath(initDirPath)\n",
        "outDirPath = f'{root_path}/audio_out'\n",
        "createPath(outDirPath)\n",
        "\n",
        "if is_colab:\n",
        "    if google_drive and not save_models_to_google_drive or not google_drive:\n",
        "        model_path = '/content/models'\n",
        "        createPath(model_path)\n",
        "    if google_drive and save_models_to_google_drive:\n",
        "        model_path = f'{root_path}/models'\n",
        "        createPath(model_path)\n",
        "else:\n",
        "    model_path = f'{root_path}/models'\n",
        "    createPath(model_path)\n",
        "\n",
        "#@markdown Click here if you'd like to save the diffusion model checkpoint file to your [Weights & Biases](www.wandb.ai/site) account:\n",
        "save_models_to_wandb = True #@param {type:\"boolean\"}\n",
        "save_wandb_str = '--save-wandb all' if save_models_to_wandb else ''\n",
        "if save_models_to_wandb == True:\n",
        "    print('Saving model checkpoints in wandb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "y9BS0ks1oEgP",
        "outputId": "a0babf71-5204-44ed-95c7-9fd78b99f011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sample-generator'...\n",
            "remote: Enumerating objects: 413, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 413 (delta 11), reused 18 (delta 7), pack-reused 389 (from 1)\u001b[K\n",
            "Receiving objects: 100% (413/413), 59.57 MiB | 33.44 MiB/s, done.\n",
            "Resolving deltas: 100% (236/236), done.\n",
            "Processing ./sample-generator\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from sample-generator==1.0.0) (0.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from sample-generator==1.0.0) (2.2.2)\n",
            "Collecting prefigure (from sample-generator==1.0.0)\n",
            "  Downloading prefigure-0.0.10-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting pytorch_lightning (from sample-generator==1.0.0)\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sample-generator==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from sample-generator==1.0.0) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from sample-generator==1.0.0) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sample-generator==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from sample-generator==1.0.0) (0.19.7)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->sample-generator==1.0.0) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->sample-generator==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->sample-generator==1.0.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->sample-generator==1.0.0) (2025.1)\n",
            "Collecting argparse (from prefigure->sample-generator==1.0.0)\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting configparser (from prefigure->sample-generator==1.0.0)\n",
            "  Downloading configparser-7.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.11/dist-packages (from prefigure->sample-generator==1.0.0) (0.5.0)\n",
            "Collecting gradio (from prefigure->sample-generator==1.0.0)\n",
            "  Downloading gradio-5.20.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning->sample-generator==1.0.0) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning->sample-generator==1.0.0) (2024.10.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning->sample-generator==1.0.0)\n",
            "  Downloading torchmetrics-1.6.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning->sample-generator==1.0.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning->sample-generator==1.0.0) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning->sample-generator==1.0.0)\n",
            "  Downloading lightning_utilities-0.13.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->sample-generator==1.0.0) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->sample-generator==1.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->sample-generator==1.0.0) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->sample-generator==1.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->sample-generator==1.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->sample-generator==1.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->sample-generator==1.0.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->sample-generator==1.0.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->sample-generator==1.0.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->sample-generator==1.0.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->sample-generator==1.0.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->sample-generator==1.0.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->sample-generator==1.0.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->sample-generator==1.0.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->sample-generator==1.0.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->sample-generator==1.0.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->sample-generator==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->sample-generator==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->sample-generator==1.0.0) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->sample-generator==1.0.0) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->sample-generator==1.0.0) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->sample-generator==1.0.0) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->sample-generator==1.0.0) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->sample-generator==1.0.0) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb->sample-generator==1.0.0) (2.10.6)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->sample-generator==1.0.0) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->sample-generator==1.0.0) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->sample-generator==1.0.0) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->sample-generator==1.0.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb->sample-generator==1.0.0) (1.17.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning->sample-generator==1.0.0) (3.11.13)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->sample-generator==1.0.0) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->sample-generator==1.0.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->sample-generator==1.0.0) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->sample-generator==1.0.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->sample-generator==1.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->sample-generator==1.0.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->sample-generator==1.0.0) (2025.1.31)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->prefigure->sample-generator==1.0.0)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->prefigure->sample-generator==1.0.0) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio->prefigure->sample-generator==1.0.0)\n",
            "  Downloading fastapi-0.115.11-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio->prefigure->sample-generator==1.0.0)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.2 (from gradio->prefigure->sample-generator==1.0.0)\n",
            "  Downloading gradio_client-1.7.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio->prefigure->sample-generator==1.0.0)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio->prefigure->sample-generator==1.0.0) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio->prefigure->sample-generator==1.0.0) (0.28.1)\n",
            "Collecting markupsafe~=2.0 (from gradio->prefigure->sample-generator==1.0.0)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->prefigure->sample-generator==1.0.0) (3.10.15)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio->prefigure->sample-generator==1.0.0) (11.1.0)\n",
            "Collecting pydub (from gradio->prefigure->sample-generator==1.0.0)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio->prefigure->sample-generator==1.0.0)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio->prefigure->sample-generator==1.0.0)\n",
            "  Downloading ruff-0.9.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio->prefigure->sample-generator==1.0.0)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio->prefigure->sample-generator==1.0.0)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio->prefigure->sample-generator==1.0.0)\n",
            "  Downloading starlette-0.46.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio->prefigure->sample-generator==1.0.0)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio->prefigure->sample-generator==1.0.0) (0.15.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->prefigure->sample-generator==1.0.0)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio->prefigure->sample-generator==1.0.0) (14.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->sample-generator==1.0.0) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->sample-generator==1.0.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->sample-generator==1.0.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->sample-generator==1.0.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->sample-generator==1.0.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->sample-generator==1.0.0) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->sample-generator==1.0.0) (1.18.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->prefigure->sample-generator==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->sample-generator==1.0.0) (5.0.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio->prefigure->sample-generator==1.0.0) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->prefigure->sample-generator==1.0.0) (0.14.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->prefigure->sample-generator==1.0.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->prefigure->sample-generator==1.0.0) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->prefigure->sample-generator==1.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->prefigure->sample-generator==1.0.0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->prefigure->sample-generator==1.0.0) (0.1.2)\n",
            "Downloading prefigure-0.0.10-py3-none-any.whl (11 kB)\n",
            "Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.13.1-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.6.2-py3-none-any.whl (931 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m931.6/931.6 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Downloading configparser-7.1.0-py3-none-any.whl (17 kB)\n",
            "Downloading gradio-5.20.1-py3-none-any.whl (62.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.2-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.11-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Building wheels for collected packages: sample-generator\n",
            "  Building wheel for sample-generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sample-generator: filename=sample_generator-1.0.0-py3-none-any.whl size=9825 sha256=c238e7c1ab678cecdd7108ee406d9433eaa30efd43ec7e0eafa8a3f165c3282a\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/f7/c4/ff0ebf3bb888b2db85b6b01d7aaaedd6173127f1e4509854b0\n",
            "Successfully built sample-generator\n",
            "Installing collected packages: pydub, argparse, uvicorn, tomlkit, semantic-version, ruff, python-multipart, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, markupsafe, lightning-utilities, groovy, ffmpy, configparser, aiofiles, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, safehttpx, nvidia-cusolver-cu12, gradio-client, fastapi, gradio, torchmetrics, pytorch_lightning, prefigure, sample-generator\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed aiofiles-23.2.1 argparse-1.4.0 configparser-7.1.0 fastapi-0.115.11 ffmpy-0.5.0 gradio-5.20.1 gradio-client-1.7.2 groovy-0.1.2 lightning-utilities-0.13.1 markupsafe-2.1.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 prefigure-0.0.10 pydub-0.25.1 python-multipart-0.0.20 pytorch_lightning-2.5.0.post0 ruff-0.9.9 safehttpx-0.1.6 sample-generator-1.0.0 semantic-version-2.10.0 starlette-0.46.0 tomlkit-0.13.2 torchmetrics-1.6.2 uvicorn-0.34.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              },
              "id": "eefde5dba2024aa5a18cd8c2d12ab67c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title Install dependencies\n",
        "!git clone https://github.com/harmonai-org/sample-generator\n",
        "!pip install /content/sample-generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xq2TJzIPTcJ"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "oxJFFEZ8CD8g",
        "outputId": "689e1e28-1392-477f-87e7-4e1d7e50810f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzcheukhei86\u001b[0m (\u001b[33mzcheukhei86-the-university-of-hong-kong\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "#@markdown Log in to [Weights & Biases](https://wandb.ai/) for run tracking\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-Q0XrS0HEmch",
        "outputId": "ce9126f7-eb44-4964-a3c5-bfb814be095b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sample-generator\n",
            "Using device: cuda\n",
            "Random crop: False\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/sample-generator/train_uncond.py\", line 228, in <module>\n",
            "    main()\n",
            "  File \"/content/sample-generator/train_uncond.py\", line 199, in main\n",
            "    train_dl = data.DataLoader(train_set, args.batch_size, shuffle=True,\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 376, in __init__\n",
            "    sampler = RandomSampler(dataset, generator=generator)  # type: ignore[arg-type]\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/sampler.py\", line 164, in __init__\n",
            "    raise ValueError(\n",
            "ValueError: num_samples should be a positive integer value, but got num_samples=0\n"
          ]
        }
      ],
      "source": [
        "#@markdown Name for the finetune project, used as the W&B project name, as well as the directory for the saved checkpoints\n",
        "NAME=\"dd-basses\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Path to the directory of audio data to use for fine-tuning\n",
        "TRAINING_DIR=\"/content/drive/MyDrive/AItrainingdata_hiphop\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Path to the checkpoint to fine-tune\n",
        "CKPT_PATH=\"/content/drive/MyDrive/AI/models/gwf-440k.ckpt\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Directory path for saving the fine-tuned outputs\n",
        "OUTPUT_DIR=\"/content/drive/MyDrive/AI/models/DanceDiffusion/finetune\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Number of training steps between demos\n",
        "DEMO_EVERY=250 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Number of training steps between saving model checkpoints\n",
        "CHECKPOINT_EVERY=500 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Sample rate to train at\n",
        "SAMPLE_RATE=44100 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Number of audio samples per training sample\n",
        "SAMPLE_SIZE=65536 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown If true, the audio samples provided will be randomly cropped to SAMPLE_SIZE samples\n",
        "#@markdown\n",
        "#@markdown Turn off if you want to ensure the training data always starts at the beginning of the audio files (good for things like drum one-shots)\n",
        "RANDOM_CROP=False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Batch size to fine-tune (make it as high as it can go for your GPU)\n",
        "BATCH_SIZE=2 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Accumulate gradients over n batches, useful for training on one GPU.\n",
        "#@markdown\n",
        "#@markdown Effective batch size is BATCH_SIZE * ACCUM_BATCHES.\n",
        "#@markdown\n",
        "#@markdown Also increases the time between demos and saved checkpoints\n",
        "ACCUM_BATCHES=4 #@param {type:\"number\"}\n",
        "\n",
        "random_crop_str = f\"--random-crop True\" if RANDOM_CROP else \"\"\n",
        "\n",
        "# Escape spaces in paths\n",
        "CKPT_PATH = CKPT_PATH.replace(f\" \", f\"\\ \")\n",
        "OUTPUT_DIR = f\"{OUTPUT_DIR}/{NAME}\".replace(f\" \", f\"\\ \")\n",
        "\n",
        "%cd /content/sample-generator/\n",
        "\n",
        "ckpt_path_str = f\"--ckpt-path {CKPT_PATH}\" if not CKPT_PATH ==\"\" else \"\"\n",
        "\n",
        "!python3 /content/sample-generator/train_uncond.py $ckpt_path_str \\\n",
        "                                                          --name \"dd-basses\" \\\n",
        "                                                          --training-dir \"/content/drive/MyDrive/AI/models/DanceDiffusion/finetune\" \\\n",
        "                                                          --sample-size 65536 \\\n",
        "                                                          --accum-batches 4 \\\n",
        "                                                          --sample-rate 44100 \\\n",
        "                                                          --batch-size 2 \\\n",
        "                                                          --demo-every 250 \\\n",
        "                                                          --checkpoint-every 500 \\\n",
        "                                                          --num-workers 2 \\\n",
        "                                                          --num-gpus 1 \\\n",
        "                                                          $random_crop_str \\\n",
        "                                                          --save-path \"/content/drive/MyDrive/AI/models/DanceDiffusion/finetune\""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j6w1wwjvItH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CewqZu2lIYMC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f488c7-093f-4611-8c12-bbe0f96e4126",
        "id": "imNo4NKWI0St"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sample-generator\n",
            "Using device: cuda\n",
            "Random crop: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzcheukhei86\u001b[0m (\u001b[33mzcheukhei86-the-university-of-hong-kong\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20250307_054949-lhmg00o2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrestful-waterfall-5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/zcheukhei86-the-university-of-hong-kong/dd-basses\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/zcheukhei86-the-university-of-hong-kong/dd-basses/runs/lhmg00o2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "/usr/local/lib/python3.11/dist-packages/lightning_fabric/connector.py:572: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "Restoring states from the checkpoint path at /content/drive/MyDrive/AI/models/gwf-440k.ckpt\n",
            "Lightning automatically upgraded your loaded checkpoint from v1.6.4 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../drive/MyDrive/AI/models/gwf-440k.ckpt`\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/call.py:277: Be aware that when using `ckpt_path`, callbacks used to create the checkpoint need to be provided during `Trainer` instantiation. Please add the following callbacks: [\"ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 2000, 'every_n_epochs': 0, 'train_time_interval': None}\"].\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name          | Type                | Params | Mode \n",
            "--------------------------------------------------------------\n",
            "0 | diffusion     | DiffusionAttnUnet1D | 221 M  | train\n",
            "1 | diffusion_ema | DiffusionAttnUnet1D | 221 M  | train\n",
            "--------------------------------------------------------------\n",
            "442 M     Trainable params\n",
            "0         Non-trainable params\n",
            "442 M     Total params\n",
            "1,771.115 Total estimated model params size (MB)\n",
            "2068      Modules in train mode\n",
            "0         Modules in eval mode\n",
            "Restored all states from the checkpoint at /content/drive/MyDrive/AI/models/gwf-440k.ckpt\n",
            "Epoch 1287:   0% 0/1 [00:00<?, ?it/s]/content/sample-generator/train_uncond.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "  0% 0/250 [00:00<?, ?it/s]\u001b[A/content/sample-generator/train_uncond.py:60: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "  0% 1/250 [00:00<04:01,  1.03it/s]\u001b[A\n",
            "  1% 2/250 [00:02<05:30,  1.33s/it]\u001b[A\n",
            "  1% 3/250 [00:04<06:08,  1.49s/it]\u001b[A\n",
            "  2% 4/250 [00:05<06:27,  1.58s/it]\u001b[A\n",
            "  2% 5/250 [00:07<06:33,  1.61s/it]\u001b[A\n",
            "  2% 6/250 [00:09<06:39,  1.64s/it]\u001b[A\n",
            "  3% 7/250 [00:10<06:41,  1.65s/it]\u001b[A\n",
            "  3% 8/250 [00:12<06:43,  1.67s/it]\u001b[A\n",
            "  4% 9/250 [00:14<06:44,  1.68s/it]\u001b[A\n",
            "  4% 10/250 [00:16<06:44,  1.69s/it]\u001b[A\n",
            "  4% 11/250 [00:17<06:44,  1.69s/it]\u001b[A\n",
            "  5% 12/250 [00:19<06:42,  1.69s/it]\u001b[A\n",
            "  5% 13/250 [00:21<06:41,  1.70s/it]\u001b[A\n",
            "  6% 14/250 [00:22<06:40,  1.70s/it]\u001b[A\n",
            "  6% 15/250 [00:24<06:39,  1.70s/it]\u001b[A\n",
            "  6% 16/250 [00:26<06:37,  1.70s/it]\u001b[A\n",
            "  7% 17/250 [00:28<06:36,  1.70s/it]\u001b[A\n",
            "  7% 18/250 [00:29<06:36,  1.71s/it]\u001b[A\n",
            "  8% 19/250 [00:31<06:35,  1.71s/it]\u001b[A\n",
            "  8% 20/250 [00:33<06:34,  1.71s/it]\u001b[A\n",
            "  8% 21/250 [00:34<06:32,  1.71s/it]\u001b[A\n",
            "  9% 22/250 [00:36<06:31,  1.72s/it]\u001b[A\n",
            "  9% 23/250 [00:38<06:30,  1.72s/it]\u001b[A\n",
            " 10% 24/250 [00:40<06:28,  1.72s/it]\u001b[A\n",
            " 10% 25/250 [00:41<06:27,  1.72s/it]\u001b[A\n",
            " 10% 26/250 [00:43<06:26,  1.73s/it]\u001b[A\n",
            " 11% 27/250 [00:45<06:25,  1.73s/it]\u001b[A\n",
            " 11% 28/250 [00:46<06:23,  1.73s/it]\u001b[A\n",
            " 12% 29/250 [00:48<06:20,  1.72s/it]\u001b[A\n",
            " 12% 30/250 [00:50<06:19,  1.73s/it]\u001b[A\n",
            " 12% 31/250 [00:52<06:17,  1.72s/it]\u001b[A\n",
            " 13% 32/250 [00:53<06:17,  1.73s/it]\u001b[A\n",
            " 13% 33/250 [00:55<06:15,  1.73s/it]\u001b[A\n",
            " 14% 34/250 [00:57<06:15,  1.74s/it]\u001b[A\n",
            " 14% 35/250 [00:59<06:12,  1.73s/it]\u001b[A\n",
            " 14% 36/250 [01:00<06:11,  1.74s/it]\u001b[A\n",
            " 15% 37/250 [01:02<06:09,  1.74s/it]\u001b[A\n",
            " 15% 38/250 [01:04<06:08,  1.74s/it]\u001b[A\n",
            " 16% 39/250 [01:06<06:06,  1.74s/it]\u001b[A\n",
            " 16% 40/250 [01:07<06:05,  1.74s/it]\u001b[A\n",
            " 16% 41/250 [01:09<06:03,  1.74s/it]\u001b[A\n",
            " 17% 42/250 [01:11<06:02,  1.74s/it]\u001b[A\n",
            " 17% 43/250 [01:13<06:00,  1.74s/it]\u001b[A\n",
            " 18% 44/250 [01:14<05:59,  1.75s/it]\u001b[A\n",
            " 18% 45/250 [01:16<05:56,  1.74s/it]\u001b[A\n",
            " 18% 46/250 [01:18<05:54,  1.74s/it]\u001b[A\n",
            " 19% 47/250 [01:19<05:54,  1.74s/it]\u001b[A\n",
            " 19% 48/250 [01:21<05:52,  1.75s/it]\u001b[A\n",
            " 20% 49/250 [01:23<05:51,  1.75s/it]\u001b[A\n",
            " 20% 50/250 [01:25<05:50,  1.75s/it]\u001b[A\n",
            " 20% 51/250 [01:27<05:50,  1.76s/it]\u001b[A\n",
            " 21% 52/250 [01:28<05:49,  1.76s/it]\u001b[A\n",
            " 21% 53/250 [01:30<05:46,  1.76s/it]\u001b[A\n",
            " 22% 54/250 [01:32<05:45,  1.76s/it]\u001b[A\n",
            " 22% 55/250 [01:34<05:44,  1.76s/it]\u001b[A\n",
            " 22% 56/250 [01:35<05:42,  1.77s/it]\u001b[A\n",
            " 23% 57/250 [01:37<05:42,  1.77s/it]\u001b[A\n",
            " 23% 58/250 [01:39<05:41,  1.78s/it]\u001b[A\n",
            " 24% 59/250 [01:41<05:40,  1.78s/it]\u001b[A\n",
            " 24% 60/250 [01:43<05:38,  1.78s/it]\u001b[A\n",
            " 24% 61/250 [01:44<05:36,  1.78s/it]\u001b[A\n",
            " 25% 62/250 [01:46<05:35,  1.79s/it]\u001b[A\n",
            " 25% 63/250 [01:48<05:34,  1.79s/it]\u001b[A\n",
            " 26% 64/250 [01:50<05:33,  1.79s/it]\u001b[A\n",
            " 26% 65/250 [01:51<05:32,  1.80s/it]\u001b[A\n",
            " 26% 66/250 [01:53<05:30,  1.80s/it]\u001b[A\n",
            " 27% 67/250 [01:55<05:29,  1.80s/it]\u001b[A\n",
            " 27% 68/250 [01:57<05:29,  1.81s/it]\u001b[A\n",
            " 28% 69/250 [01:59<05:26,  1.80s/it]\u001b[A\n",
            " 28% 70/250 [02:01<05:25,  1.81s/it]\u001b[A\n",
            " 28% 71/250 [02:02<05:24,  1.81s/it]\u001b[A\n",
            " 29% 72/250 [02:04<05:23,  1.82s/it]\u001b[A\n",
            " 29% 73/250 [02:06<05:22,  1.82s/it]\u001b[A\n",
            " 30% 74/250 [02:08<05:22,  1.83s/it]\u001b[A\n",
            " 30% 75/250 [02:10<05:21,  1.84s/it]\u001b[A\n",
            " 30% 76/250 [02:12<05:19,  1.83s/it]\u001b[A\n",
            " 31% 77/250 [02:13<05:17,  1.84s/it]\u001b[A\n",
            " 31% 78/250 [02:15<05:16,  1.84s/it]\u001b[A\n",
            " 32% 79/250 [02:17<05:14,  1.84s/it]\u001b[A\n",
            " 32% 80/250 [02:19<05:13,  1.84s/it]\u001b[A\n",
            " 32% 81/250 [02:21<05:12,  1.85s/it]\u001b[A\n",
            " 33% 82/250 [02:23<05:11,  1.85s/it]\u001b[A\n",
            " 33% 83/250 [02:25<05:10,  1.86s/it]\u001b[A\n",
            " 34% 84/250 [02:26<05:08,  1.86s/it]\u001b[A\n",
            " 34% 85/250 [02:28<05:06,  1.86s/it]\u001b[A\n",
            " 34% 86/250 [02:30<05:05,  1.86s/it]\u001b[A\n",
            " 35% 87/250 [02:32<05:03,  1.86s/it]\u001b[A\n",
            " 35% 88/250 [02:34<05:01,  1.86s/it]\u001b[A\n",
            " 36% 89/250 [02:36<04:59,  1.86s/it]\u001b[A\n",
            " 36% 90/250 [02:38<04:57,  1.86s/it]\u001b[A\n",
            " 36% 91/250 [02:39<04:54,  1.85s/it]\u001b[A\n",
            " 37% 92/250 [02:41<04:52,  1.85s/it]\u001b[A\n",
            " 37% 93/250 [02:43<04:50,  1.85s/it]\u001b[A\n",
            " 38% 94/250 [02:45<04:48,  1.85s/it]\u001b[A\n",
            " 38% 95/250 [02:47<04:45,  1.84s/it]\u001b[A\n",
            " 38% 96/250 [02:49<04:44,  1.84s/it]\u001b[A\n",
            " 39% 97/250 [02:50<04:42,  1.84s/it]\u001b[A\n",
            " 39% 98/250 [02:52<04:40,  1.85s/it]\u001b[A\n",
            " 40% 99/250 [02:54<04:38,  1.84s/it]\u001b[A\n",
            " 40% 100/250 [02:56<04:36,  1.84s/it]\u001b[A\n",
            " 40% 101/250 [02:58<04:34,  1.84s/it]\u001b[A\n",
            " 41% 102/250 [03:00<04:32,  1.84s/it]\u001b[A\n",
            " 41% 103/250 [03:02<04:30,  1.84s/it]\u001b[A\n",
            " 42% 104/250 [03:03<04:29,  1.84s/it]\u001b[A\n",
            " 42% 105/250 [03:05<04:27,  1.84s/it]\u001b[A\n",
            " 42% 106/250 [03:07<04:25,  1.84s/it]\u001b[A\n",
            " 43% 107/250 [03:09<04:23,  1.84s/it]\u001b[A\n",
            " 43% 108/250 [03:11<04:21,  1.84s/it]\u001b[A\n",
            " 44% 109/250 [03:13<04:19,  1.84s/it]\u001b[A\n",
            " 44% 110/250 [03:14<04:18,  1.84s/it]\u001b[A\n",
            " 44% 111/250 [03:16<04:15,  1.84s/it]\u001b[A\n",
            " 45% 112/250 [03:18<04:14,  1.84s/it]\u001b[A\n",
            " 45% 113/250 [03:20<04:12,  1.84s/it]\u001b[A\n",
            " 46% 114/250 [03:22<04:10,  1.84s/it]\u001b[A\n",
            " 46% 115/250 [03:24<04:09,  1.85s/it]\u001b[A\n",
            " 46% 116/250 [03:25<04:07,  1.85s/it]\u001b[A\n",
            " 47% 117/250 [03:27<04:05,  1.85s/it]\u001b[A\n",
            " 47% 118/250 [03:29<04:03,  1.85s/it]\u001b[A\n",
            " 48% 119/250 [03:31<04:02,  1.85s/it]\u001b[A\n",
            " 48% 120/250 [03:33<04:00,  1.85s/it]\u001b[A\n",
            " 48% 121/250 [03:35<03:59,  1.85s/it]\u001b[A\n",
            " 49% 122/250 [03:37<03:56,  1.85s/it]\u001b[A\n",
            " 49% 123/250 [03:38<03:54,  1.85s/it]\u001b[A\n",
            " 50% 124/250 [03:40<03:52,  1.85s/it]\u001b[A\n",
            " 50% 125/250 [03:42<03:50,  1.85s/it]\u001b[A\n",
            " 50% 126/250 [03:44<03:48,  1.84s/it]\u001b[A\n",
            " 51% 127/250 [03:46<03:47,  1.85s/it]\u001b[A\n",
            " 51% 128/250 [03:48<03:45,  1.85s/it]\u001b[A\n",
            " 52% 129/250 [03:49<03:43,  1.85s/it]\u001b[A\n",
            " 52% 130/250 [03:51<03:41,  1.85s/it]\u001b[A\n",
            " 52% 131/250 [03:53<03:40,  1.85s/it]\u001b[A\n",
            " 53% 132/250 [03:55<03:38,  1.85s/it]\u001b[A\n",
            " 53% 133/250 [03:57<03:36,  1.85s/it]\u001b[A\n",
            " 54% 134/250 [03:59<03:34,  1.85s/it]\u001b[A\n",
            " 54% 135/250 [04:01<03:32,  1.85s/it]\u001b[A\n",
            " 54% 136/250 [04:02<03:30,  1.85s/it]\u001b[A\n",
            " 55% 137/250 [04:04<03:28,  1.84s/it]\u001b[A\n",
            " 55% 138/250 [04:06<03:26,  1.84s/it]\u001b[A\n",
            " 56% 139/250 [04:08<03:25,  1.85s/it]\u001b[A\n",
            " 56% 140/250 [04:10<03:23,  1.85s/it]\u001b[A\n",
            " 56% 141/250 [04:12<03:21,  1.85s/it]\u001b[A\n",
            " 57% 142/250 [04:14<03:19,  1.85s/it]\u001b[A\n",
            " 57% 143/250 [04:15<03:18,  1.85s/it]\u001b[A\n",
            " 58% 144/250 [04:17<03:16,  1.85s/it]\u001b[A\n",
            " 58% 145/250 [04:19<03:14,  1.86s/it]\u001b[A\n",
            " 58% 146/250 [04:21<03:13,  1.86s/it]\u001b[A\n",
            " 59% 147/250 [04:23<03:10,  1.85s/it]\u001b[A\n",
            " 59% 148/250 [04:25<03:09,  1.85s/it]\u001b[A\n",
            " 60% 149/250 [04:27<03:07,  1.86s/it]\u001b[A\n",
            " 60% 150/250 [04:28<03:05,  1.85s/it]\u001b[A\n",
            " 60% 151/250 [04:30<03:04,  1.86s/it]\u001b[A\n",
            " 61% 152/250 [04:32<03:01,  1.86s/it]\u001b[A\n",
            " 61% 153/250 [04:34<03:00,  1.86s/it]\u001b[A\n",
            " 62% 154/250 [04:36<02:58,  1.86s/it]\u001b[A\n",
            " 62% 155/250 [04:38<02:56,  1.86s/it]\u001b[A\n",
            " 62% 156/250 [04:40<02:54,  1.86s/it]\u001b[A\n",
            " 63% 157/250 [04:41<02:53,  1.86s/it]\u001b[A\n",
            " 63% 158/250 [04:43<02:51,  1.86s/it]\u001b[A\n",
            " 64% 159/250 [04:45<02:49,  1.86s/it]\u001b[A\n",
            " 64% 160/250 [04:47<02:47,  1.86s/it]\u001b[A\n",
            " 64% 161/250 [04:49<02:45,  1.86s/it]\u001b[A\n",
            " 65% 162/250 [04:51<02:43,  1.86s/it]\u001b[A\n",
            " 65% 163/250 [04:53<02:41,  1.86s/it]\u001b[A\n",
            " 66% 164/250 [04:54<02:40,  1.86s/it]\u001b[A\n",
            " 66% 165/250 [04:56<02:38,  1.86s/it]\u001b[A\n",
            " 66% 166/250 [04:58<02:36,  1.87s/it]\u001b[A\n",
            " 67% 167/250 [05:00<02:34,  1.86s/it]\u001b[A\n",
            " 67% 168/250 [05:02<02:32,  1.86s/it]\u001b[A\n",
            " 68% 169/250 [05:04<02:30,  1.86s/it]\u001b[A\n",
            " 68% 170/250 [05:06<02:29,  1.86s/it]\u001b[A\n",
            " 68% 171/250 [05:07<02:27,  1.86s/it]\u001b[A\n",
            " 69% 172/250 [05:09<02:25,  1.86s/it]\u001b[A\n",
            " 69% 173/250 [05:11<02:23,  1.86s/it]\u001b[A\n",
            " 70% 174/250 [05:13<02:21,  1.86s/it]\u001b[A\n",
            " 70% 175/250 [05:15<02:19,  1.86s/it]\u001b[A\n",
            " 70% 176/250 [05:17<02:17,  1.86s/it]\u001b[A\n",
            " 71% 177/250 [05:19<02:15,  1.86s/it]\u001b[A\n",
            " 71% 178/250 [05:21<02:14,  1.86s/it]\u001b[A\n",
            " 72% 179/250 [05:22<02:12,  1.86s/it]\u001b[A\n",
            " 72% 180/250 [05:24<02:10,  1.86s/it]\u001b[A\n",
            " 72% 181/250 [05:26<02:08,  1.87s/it]\u001b[A\n",
            " 73% 182/250 [05:28<02:06,  1.86s/it]\u001b[A\n",
            " 73% 183/250 [05:30<02:04,  1.86s/it]\u001b[A\n",
            " 74% 184/250 [05:32<02:02,  1.86s/it]\u001b[A\n",
            " 74% 185/250 [05:34<02:01,  1.86s/it]\u001b[A\n",
            " 74% 186/250 [05:35<01:59,  1.86s/it]\u001b[A\n",
            " 75% 187/250 [05:37<01:57,  1.86s/it]\u001b[A\n",
            " 75% 188/250 [05:39<01:55,  1.86s/it]\u001b[A\n",
            " 76% 189/250 [05:41<01:53,  1.86s/it]\u001b[A\n",
            " 76% 190/250 [05:43<01:51,  1.86s/it]\u001b[A\n",
            " 76% 191/250 [05:45<01:49,  1.86s/it]\u001b[A\n",
            " 77% 192/250 [05:47<01:47,  1.86s/it]\u001b[A\n",
            " 77% 193/250 [05:48<01:46,  1.86s/it]\u001b[A\n",
            " 78% 194/250 [05:50<01:44,  1.86s/it]\u001b[A\n",
            " 78% 195/250 [05:52<01:42,  1.86s/it]\u001b[A\n",
            " 78% 196/250 [05:54<01:40,  1.86s/it]\u001b[A\n",
            " 79% 197/250 [05:56<01:38,  1.86s/it]\u001b[A\n",
            " 79% 198/250 [05:58<01:36,  1.86s/it]\u001b[A\n",
            " 80% 199/250 [06:00<01:34,  1.86s/it]\u001b[A\n",
            " 80% 200/250 [06:01<01:33,  1.86s/it]\u001b[A\n",
            " 80% 201/250 [06:03<01:30,  1.86s/it]\u001b[A\n",
            " 81% 202/250 [06:05<01:29,  1.86s/it]\u001b[A\n",
            " 81% 203/250 [06:07<01:27,  1.86s/it]\u001b[A\n",
            " 82% 204/250 [06:09<01:25,  1.85s/it]\u001b[A\n",
            " 82% 205/250 [06:11<01:23,  1.85s/it]\u001b[A\n",
            " 82% 206/250 [06:13<01:21,  1.86s/it]\u001b[A\n",
            " 83% 207/250 [06:14<01:19,  1.86s/it]\u001b[A\n",
            " 83% 208/250 [06:16<01:17,  1.85s/it]\u001b[A\n",
            " 84% 209/250 [06:18<01:16,  1.86s/it]\u001b[A\n",
            " 84% 210/250 [06:20<01:14,  1.86s/it]\u001b[A\n",
            " 84% 211/250 [06:22<01:12,  1.86s/it]\u001b[A\n",
            " 85% 212/250 [06:24<01:10,  1.86s/it]\u001b[A\n",
            " 85% 213/250 [06:26<01:08,  1.86s/it]\u001b[A\n",
            " 86% 214/250 [06:27<01:06,  1.86s/it]\u001b[A\n",
            " 86% 215/250 [06:29<01:05,  1.86s/it]\u001b[A\n",
            " 86% 216/250 [06:31<01:03,  1.86s/it]\u001b[A\n",
            " 87% 217/250 [06:33<01:01,  1.86s/it]\u001b[A\n",
            " 87% 218/250 [06:35<00:59,  1.86s/it]\u001b[A\n",
            " 88% 219/250 [06:37<00:57,  1.86s/it]\u001b[A\n",
            " 88% 220/250 [06:39<00:55,  1.86s/it]\u001b[A\n",
            " 88% 221/250 [06:40<00:53,  1.86s/it]\u001b[A\n",
            " 89% 222/250 [06:42<00:52,  1.86s/it]\u001b[A\n",
            " 89% 223/250 [06:44<00:50,  1.86s/it]\u001b[A\n",
            " 90% 224/250 [06:46<00:48,  1.86s/it]\u001b[A\n",
            " 90% 225/250 [06:48<00:46,  1.86s/it]\u001b[A\n",
            " 90% 226/250 [06:50<00:44,  1.87s/it]\u001b[A\n",
            " 91% 227/250 [06:52<00:42,  1.86s/it]\u001b[A\n",
            " 91% 228/250 [06:53<00:40,  1.86s/it]\u001b[A\n",
            " 92% 229/250 [06:55<00:39,  1.86s/it]\u001b[A\n",
            " 92% 230/250 [06:57<00:37,  1.86s/it]\u001b[A\n",
            " 92% 231/250 [06:59<00:35,  1.86s/it]\u001b[A\n",
            " 93% 232/250 [07:01<00:33,  1.86s/it]\u001b[A\n",
            " 93% 233/250 [07:03<00:31,  1.86s/it]\u001b[A\n",
            " 94% 234/250 [07:05<00:29,  1.85s/it]\u001b[A\n",
            " 94% 235/250 [07:06<00:27,  1.86s/it]\u001b[A\n",
            " 94% 236/250 [07:08<00:26,  1.86s/it]\u001b[A\n",
            " 95% 237/250 [07:10<00:24,  1.86s/it]\u001b[A\n",
            " 95% 238/250 [07:12<00:22,  1.85s/it]\u001b[A\n",
            " 96% 239/250 [07:14<00:20,  1.85s/it]\u001b[A\n",
            " 96% 240/250 [07:16<00:18,  1.85s/it]\u001b[A\n",
            " 96% 241/250 [07:18<00:16,  1.85s/it]\u001b[A\n",
            " 97% 242/250 [07:19<00:14,  1.85s/it]\u001b[A\n",
            " 97% 243/250 [07:21<00:12,  1.85s/it]\u001b[A\n",
            " 98% 244/250 [07:23<00:11,  1.85s/it]\u001b[A\n",
            " 98% 245/250 [07:25<00:09,  1.85s/it]\u001b[A\n",
            " 98% 246/250 [07:27<00:07,  1.85s/it]\u001b[A\n",
            " 99% 247/250 [07:29<00:05,  1.85s/it]\u001b[A\n",
            " 99% 248/250 [07:31<00:03,  1.85s/it]\u001b[A\n",
            "100% 249/250 [07:32<00:01,  1.85s/it]\u001b[A\n",
            "100% 250/250 [07:34<00:00,  1.82s/it]\n",
            "/usr/local/lib/python3.11/dist-packages/torchaudio/transforms/_transforms.py:580: UserWarning: Argument 'onesided' has been deprecated and has no influence on the behavior of this module.\n",
            "  warnings.warn(\n",
            "Epoch 1288:   0% 0/1 [00:00<?, ?it/s, v_num=00o2, train/loss=0.000271, train/mse_loss=0.000271]/content/sample-generator/train_uncond.py:119: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 1537:   0% 0/1 [00:00<?, ?it/s, v_num=00o2, train/loss=0.00097, train/mse_loss=0.00097]\n",
            "  0% 0/250 [00:00<?, ?it/s]\u001b[A/content/sample-generator/train_uncond.py:60: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "  0% 1/250 [00:00<03:44,  1.11it/s]\u001b[A\n",
            "  1% 2/250 [00:02<06:02,  1.46s/it]\u001b[A\n",
            "  1% 3/250 [00:04<06:43,  1.64s/it]\u001b[A\n",
            "  2% 4/250 [00:06<07:05,  1.73s/it]\u001b[A\n",
            "  2% 5/250 [00:08<07:15,  1.78s/it]\u001b[A\n",
            "  2% 6/250 [00:10<07:20,  1.80s/it]\u001b[A\n",
            "  3% 7/250 [00:12<07:22,  1.82s/it]\u001b[A\n",
            "  3% 8/250 [00:13<07:23,  1.83s/it]\u001b[A\n",
            "  4% 9/250 [00:15<07:25,  1.85s/it]\u001b[A\n",
            "  4% 10/250 [00:17<07:23,  1.85s/it]\u001b[A\n",
            "  4% 11/250 [00:19<07:22,  1.85s/it]\u001b[A"
          ]
        }
      ],
      "source": [
        "#@markdown Name for the finetune project, used as the W&B project name, as well as the directory for the saved checkpoints\n",
        "NAME=\"dd-basses\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Path to the directory of audio data to use for fine-tuning\n",
        "TRAINING_DIR=\"/content/drive/MyDrive/AItrainingdata_hiphop\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Path to the checkpoint to fine-tune\n",
        "CKPT_PATH=\"/content/drive/MyDrive/AI/models/gwf-440k.ckpt\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Directory path for saving the fine-tuned outputs\n",
        "OUTPUT_DIR=\"/content/drive/MyDrive/AI/models/DanceDiffusion/finetune\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Number of training steps between demos\n",
        "DEMO_EVERY=250 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Number of training steps between saving model checkpoints\n",
        "CHECKPOINT_EVERY=500 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Sample rate to train at\n",
        "SAMPLE_RATE=44100 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Number of audio samples per training sample\n",
        "SAMPLE_SIZE=65536 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown If true, the audio samples provided will be randomly cropped to SAMPLE_SIZE samples\n",
        "#@markdown\n",
        "#@markdown Turn off if you want to ensure the training data always starts at the beginning of the audio files (good for things like drum one-shots)\n",
        "RANDOM_CROP=False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Batch size to fine-tune (make it as high as it can go for your GPU)\n",
        "BATCH_SIZE=2 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Accumulate gradients over n batches, useful for training on one GPU.\n",
        "#@markdown\n",
        "#@markdown Effective batch size is BATCH_SIZE * ACCUM_BATCHES.\n",
        "#@markdown\n",
        "#@markdown Also increases the time between demos and saved checkpoints\n",
        "ACCUM_BATCHES=4 #@param {type:\"number\"}\n",
        "\n",
        "random_crop_str = f\"--random-crop True\" if RANDOM_CROP else \"\"\n",
        "\n",
        "# Escape spaces in paths\n",
        "CKPT_PATH = CKPT_PATH.replace(f\" \", f\"\\ \")\n",
        "OUTPUT_DIR = f\"{OUTPUT_DIR}/{NAME}\".replace(f\" \", f\"\\ \")\n",
        "\n",
        "%cd /content/sample-generator/\n",
        "\n",
        "ckpt_path_str = f\"--ckpt-path {CKPT_PATH}\" if not CKPT_PATH ==\"\" else \"\"\n",
        "\n",
        "!python3 /content/sample-generator/train_uncond.py $ckpt_path_str \\\n",
        "                                                          --name \"dd-basses\" \\\n",
        "                                                          --training-dir \"/content/drive/MyDrive/AItrainingdata_hiphop\" \\\n",
        "                                                          --sample-size 65536 \\\n",
        "                                                          --accum-batches 4 \\\n",
        "                                                          --sample-rate 44100 \\\n",
        "                                                          --batch-size 2 \\\n",
        "                                                          --demo-every 250 \\\n",
        "                                                          --checkpoint-every 500 \\\n",
        "                                                          --num-workers 2 \\\n",
        "                                                          --num-gpus 1 \\\n",
        "                                                          $random_crop_str \\\n",
        "                                                          --save-path \"/content/drive/MyDrive/AI/models/DanceDiffusion/finetune\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "HHcTRGvUmoME"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.8 ('ml')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "9ce29cb5aeaaebb09d381145ff1103741c9816dbccbfcb1b857cd83265b8bd84"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}